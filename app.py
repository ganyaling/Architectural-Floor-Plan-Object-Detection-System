"""
FastAPI åç«¯æœåŠ¡ - ç”¨äºæ¨¡å‹æ¨ç†
æ”¯æŒä¸Šä¼ å›¾ç‰‡å¹¶è¿”å›æ£€æµ‹ç»“æœ
"""

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from PIL import Image
import torch
import io
import json
from pathlib import Path
from typing import List, Dict
import uvicorn

from simple_inference import DetectionInference

# åˆå§‹åŒ– FastAPI
app = FastAPI(
    title="å»ºç­‘å¹³é¢å›¾ç›®æ ‡æ£€æµ‹ API",
    description="ç”¨äºæ£€æµ‹å»ºç­‘å¹³é¢å›¾ä¸­çš„å¢™å£å’Œæˆ¿é—´",
    version="1.0.0"
)

# æ·»åŠ  CORS æ”¯æŒï¼ˆå…è®¸å‰ç«¯è·¨åŸŸè¯·æ±‚ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æº
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡ï¼šæ¨ç†å¼•æ“
inferencer = None

# æ¨¡å‹é…ç½®
MODEL_CONFIG = {
    'checkpoint_path': './pytorch_detection_results/best_model.pth',
    'conf_threshold': 0.5,
    'device': 'cuda:0'
}


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹"""
    global inferencer
    try:
        print("ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹...")
        inferencer = DetectionInference(
            checkpoint_path=MODEL_CONFIG['checkpoint_path'],
            device=MODEL_CONFIG['device'],
            conf_threshold=MODEL_CONFIG['conf_threshold']
        )
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise


@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶æ¸…ç†èµ„æº"""
    print("ğŸ”´ åº”ç”¨å…³é—­")


@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "ok",
        "message": "å»ºç­‘å¹³é¢å›¾ç›®æ ‡æ£€æµ‹ API æ­£åœ¨è¿è¡Œ",
        "version": "1.0.0"
    }


@app.post("/detect")
async def detect_objects(file: UploadFile = File(...), conf_threshold: float = 0.5):
    """
    ä¸Šä¼ å›¾ç‰‡è¿›è¡Œç›®æ ‡æ£€æµ‹
    
    å‚æ•°:
        file: ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶ (PNG, JPG)
        conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼ (0.0-1.0)
    
    è¿”å›:
        {
            "status": "success",
            "image_size": [width, height],
            "detections": [
                {
                    "bbox": [x1, y1, x2, y2],
                    "category": 1,
                    "category_name": "wall",
                    "confidence": 0.95
                },
                ...
            ],
            "summary": {
                "wall": 28,
                "room": 17
            }
        }
    """
    try:
        if inferencer is None:
            raise HTTPException(status_code=500, detail="æ¨¡å‹æœªåŠ è½½")
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if file.content_type not in ['image/png', 'image/jpeg', 'image/jpg']:
            raise HTTPException(status_code=400, detail="ä»…æ”¯æŒ PNG æˆ– JPG æ ¼å¼")
        
        # è¯»å–ä¸Šä¼ çš„æ–‡ä»¶
        contents = await file.read()
        image = Image.open(io.BytesIO(contents)).convert('RGB')
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶ä»¥ä¾¿æ¨ç†
        temp_path = f"temp_{file.filename}"
        image.save(temp_path)
        
        # æ‰§è¡Œæ¨ç†
        results = inferencer.infer_single(temp_path, score_threshold=conf_threshold)
        
        # ç»Ÿè®¡æ£€æµ‹ç»“æœ
        summary = {}
        for det in results['detections']:
            cat_name = det['category_name']
            summary[cat_name] = summary.get(cat_name, 0) + 1
        
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        Path(temp_path).unlink()
        
        return {
            "status": "success",
            "image_size": results['image_size'],
            "detections": results['detections'],
            "summary": summary,
            "total": len(results['detections'])
        }
    
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"æ¨ç†å¤±è´¥: {str(e)}")


@app.post("/detect-with-visualization")
async def detect_with_visualization(file: UploadFile = File(...), conf_threshold: float = 0.5):
    """
    ä¸Šä¼ å›¾ç‰‡è¿›è¡Œæ£€æµ‹å¹¶è¿”å›å¯è§†åŒ–ç»“æœ
    
    è¿”å›: å¸¦æœ‰æ£€æµ‹æ¡†çš„å›¾ç‰‡æ–‡ä»¶
    """
    try:
        if inferencer is None:
            raise HTTPException(status_code=500, detail="æ¨¡å‹æœªåŠ è½½")
        
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if file.content_type not in ['image/png', 'image/jpeg', 'image/jpg']:
            raise HTTPException(status_code=400, detail="ä»…æ”¯æŒ PNG æˆ– JPG æ ¼å¼")
        
        # è¯»å–ä¸Šä¼ çš„æ–‡ä»¶
        contents = await file.read()
        image = Image.open(io.BytesIO(contents)).convert('RGB')
        
        # ä¿å­˜ä¸´æ—¶è¾“å…¥æ–‡ä»¶
        temp_input = f"temp_input_{file.filename}"
        image.save(temp_input)
        
        # ç»˜åˆ¶æ£€æµ‹ç»“æœ
        temp_output = f"temp_output_{file.filename}"
        inferencer.draw_predictions(temp_input, temp_output, conf_threshold)
        
        # è¯»å–è¾“å‡ºå›¾ç‰‡
        response = FileResponse(
            temp_output,
            media_type='image/png',
            filename=f"detected_{file.filename}"
        )
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        Path(temp_input).unlink(missing_ok=True)
        
        return response
    
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"æ¨ç†å¤±è´¥: {str(e)}")


@app.get("/model-info")
async def model_info():
    """è·å–æ¨¡å‹ä¿¡æ¯"""
    return {
        "model_name": "Faster R-CNN + ResNet50",
        "classes": {
            0: "background",
            1: "wall",
            2: "room"
        },
        "checkpoint": MODEL_CONFIG['checkpoint_path'],
        "device": MODEL_CONFIG['device'],
        "conf_threshold": MODEL_CONFIG['conf_threshold']
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "healthy",
        "model_loaded": inferencer is not None
    }


if __name__ == "__main__":
    # å¯åŠ¨æœåŠ¡å™¨
    # ä½¿ç”¨ uvicorn è¿è¡Œ: python app.py
    # æˆ–å‘½ä»¤è¡Œ: uvicorn app:app --host 0.0.0.0 --port 8000 --reload
    
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘       å»ºç­‘å¹³é¢å›¾ç›®æ ‡æ£€æµ‹ API æœåŠ¡                                  â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  API æ–‡æ¡£:   http://localhost:8000/docs                      â•‘
    â•‘  Swagger UI: http://localhost:8000/docs                      â•‘
    â•‘  ReDoc:      http://localhost:8000/redoc                     â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        reload=False
    )
