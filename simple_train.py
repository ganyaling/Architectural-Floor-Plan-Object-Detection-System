"""
PyTorch åŸç”Ÿ Faster R-CNN è®­ç»ƒè„šæœ¬
ç”¨äº CubiCasa5K æ•°æ®é›†çš„ç›®æ ‡æ£€æµ‹è®­ç»ƒ
æ— éœ€ MMDetection å¤æ‚ä¾èµ–
"""

import argparse
import os
import sys
from pathlib import Path
import json
import warnings
from collections import defaultdict

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torch.optim as optim
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.transforms import transforms, functional as F
import numpy as np
import cv2
from tqdm import tqdm
from PIL import Image
import pycocotools.coco as coco
from pycocotools.cocoeval import COCOeval
import json
import albumentations as A
from albumentations.pytorch.transforms import ToTensorV2
from torch.cuda.amp import autocast, GradScaler

warnings.filterwarnings('ignore')


class COCODetectionDataset(Dataset):
    """COCO æ ¼å¼çš„ç›®æ ‡æ£€æµ‹æ•°æ®é›†"""
    
    def __init__(self, img_dir, ann_file, transforms=None):
        """
        Args:
            img_dir: å›¾åƒç›®å½•è·¯å¾„ï¼ˆæˆ–çˆ¶ç›®å½•ï¼‰
            ann_file: COCO æ ‡æ³¨æ–‡ä»¶è·¯å¾„ (JSON)
            transforms: æ•°æ®å¢å¼ºè½¬æ¢
        """
        self.img_dir = Path(img_dir)
        self.coco = coco.COCO(ann_file)
        self.ids = list(sorted(self.coco.imgs.keys()))
        self.transforms = transforms
        
        # æ£€æŸ¥å¹¶ç¡®å®šå®é™…çš„å›¾åƒè·¯å¾„
        self._setup_img_paths()
    
    def _setup_img_paths(self):
        """è®¾ç½®å›¾åƒè·¯å¾„ - è‡ªåŠ¨å¤„ç† cubicasa5k çš„åµŒå¥—ç»“æ„"""
        # cubicasa5k çš„å®é™…å›¾åƒåœ¨ cubicasa5k/cubicasa5k/cubicasa5k ä¸‹ï¼ˆä¸‰å±‚åµŒå¥—ï¼‰
        possible_dirs = [
            self.img_dir,
            self.img_dir / 'cubicasa5k',
            self.img_dir / 'cubicasa5k' / 'cubicasa5k',
        ]
        
        for img_dir in possible_dirs:
            if img_dir.exists():
                # æ£€æŸ¥æ˜¯å¦èƒ½æ‰¾åˆ°ç¬¬ä¸€ä¸ªå›¾åƒ
                test_file = self.coco.imgs[self.ids[0]]['file_name']
                # æ¸…ç†æ–‡ä»¶åä¸­çš„å‰ç¼€
                test_file_clean = test_file.lstrip('/')
                if test_file_clean.startswith('kaggle/'):
                    test_file_clean = test_file_clean.replace('kaggle/input/cubicasa5k/cubicasa5k/cubicasa5k/', '', 1)
                
                # è½¬æ¢æ­£æ–œæ ä¸ºåæ–œæ 
                test_file_clean = test_file_clean.replace('/', '\\')
                test_path = img_dir / test_file_clean
                
                if test_path.exists():
                    self.img_dir = img_dir
                    print(f"âœ… ä½¿ç”¨å›¾åƒç›®å½•: {self.img_dir}")
                    return
        
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œä½¿ç”¨åŸå§‹ç›®å½•å¹¶æ‰“å°è­¦å‘Š
        print(f"âš ï¸  è­¦å‘Š: æ— æ³•è‡ªåŠ¨å®šä½å›¾åƒç›®å½•ï¼Œä½¿ç”¨æŒ‡å®šè·¯å¾„: {self.img_dir}")
    
    def __len__(self):
        return len(self.ids)
    
    def _get_img_path(self, file_name):
        """è·å–å›¾åƒçš„å®Œæ•´è·¯å¾„"""
        # æ¸…ç† file_name ä¸­çš„ç‰¹æ®Šå‰ç¼€
        file_name = file_name.lstrip('/')
        
        # å¤„ç† Kaggle æ ¼å¼çš„è·¯å¾„
        if file_name.startswith('kaggle/'):
            file_name = file_name.replace('kaggle/input/cubicasa5k/cubicasa5k/cubicasa5k/', '', 1)
            if file_name.startswith('/'):
                file_name = file_name.lstrip('/')
        
        # å°†è·¯å¾„ä¸­çš„æ­£æ–œæ è½¬æ¢ä¸ºç³»ç»Ÿæ–œæ 
        file_name = file_name.replace('/', '\\')
        
        img_path = self.img_dir / file_name
        return img_path
    
    def __getitem__(self, idx):
        img_id = self.ids[idx]
        img_info = self.coco.loadImgs(img_id)[0]
        
        # è·å–å›¾åƒè·¯å¾„
        img_path = self._get_img_path(img_info['file_name'])
        
        # åŠ è½½å›¾åƒ
        if not img_path.exists():
            print(f"\nâŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨:")
            print(f"   åŸå§‹åç§°: {img_info['file_name']}")
            print(f"   æœŸæœ›è·¯å¾„: {img_path}")
            print(f"   å›¾åƒç›®å½•: {self.img_dir}")
            raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
        
        image = Image.open(img_path).convert('RGB')
        image = np.array(image)
        
        # è‡ªåŠ¨ç¼©æ”¾å¤§å›¾åƒä»¥èŠ‚çœæ˜¾å­˜
        max_size = 1024  # æœ€å¤§å°ºå¯¸
        h, w = image.shape[:2]
        if w > max_size or h > max_size:
            scale = max_size / max(w, h)
            new_h, new_w = int(h * scale), int(w * scale)
            import cv2
            image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
        
        # è·å–æ ‡æ³¨
        ann_ids = self.coco.getAnnIds(imgIds=img_id)
        anns = self.coco.loadAnns(ann_ids)
        
        # è§£æ bbox å’Œ category (æ ¼å¼: [x1, y1, x2, y2])
        bboxes = []
        class_labels = []
        img_h, img_w = image.shape[:2]
        
        for ann in anns:
            if ann['iscrowd']:
                continue
            x, y, w, h = ann['bbox']
            x1, y1, x2, y2 = x, y, x + w, y + h
            
            # ä¿®å‰ª bbox åˆ°å›¾åƒèŒƒå›´å†…
            x1 = max(0, min(x1, img_w - 1))
            y1 = max(0, min(y1, img_h - 1))
            x2 = max(0, min(x2, img_w - 1))
            y2 = max(0, min(y2, img_h - 1))
            
            # ä¸¢å¼ƒæ— æ•ˆ bboxï¼ˆå¤ªå°æˆ–åæ ‡æ— æ•ˆï¼‰
            if x2 - x1 > 5 and y2 - y1 > 5 and x1 < x2 and y1 < y2:
                bboxes.append([x1, y1, x2, y2])
                class_labels.append(ann['category_id'])
        
        # åº”ç”¨ Albumentations å˜æ¢
        if self.transforms:
            transformed = self.transforms(
                image=image,
                bboxes=bboxes,
                class_labels=class_labels
            )
            image = transformed['image']  # å·²æ˜¯ tensor
            bboxes = transformed['bboxes']
            class_labels = transformed['class_labels']
        
        # è½¬æ¢ä¸º tensor
        if len(bboxes) > 0:
            boxes = torch.as_tensor(bboxes, dtype=torch.float32)
            labels = torch.as_tensor(class_labels, dtype=torch.int64)
        else:
            boxes = torch.zeros((0, 4), dtype=torch.float32)
            labels = torch.zeros((0,), dtype=torch.int64)
        
        # å¦‚æœæ²¡æœ‰ transformsï¼Œéœ€è¦æ‰‹åŠ¨è½¬å¼ é‡
        if not self.transforms:
            image = transforms.ToTensor()(Image.fromarray(image))
        
        target = {
            'boxes': boxes,
            'labels': labels,
            'image_id': torch.tensor([img_id]),
        }
        
        return image, target


class Trainer:
    """è®­ç»ƒå™¨"""
    
    def __init__(self, args):
        self.args = args
        self.device = torch.device(f'cuda:{args.gpu}' if torch.cuda.is_available() else 'cpu')
        self.work_dir = Path(args.work_dir)
        self.work_dir.mkdir(parents=True, exist_ok=True)
        
        # FP16 è®­ç»ƒç›¸å…³
        self.use_fp16 = torch.cuda.is_available() and args.use_fp16
        self.scaler = GradScaler() if self.use_fp16 else None
        
        print(f"âœ… ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"âœ… å·¥ä½œç›®å½•: {self.work_dir}")
        if self.use_fp16:
            print(f"âœ… å¯ç”¨ FP16 åŠç²¾åº¦è®­ç»ƒ")
    
    def get_model(self, num_classes=3):
        """è·å–é¢„è®­ç»ƒæ¨¡å‹ - ä½¿ç”¨è¿ç§»å­¦ä¹ """
        # ç¬¬ä¸€æ­¥ï¼šåŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆCOCO 91ç±»åˆ«ï¼‰
        model = fasterrcnn_resnet50_fpn(pretrained=True, num_classes=91)
        
        # ç¬¬äºŒæ­¥ï¼šæ›¿æ¢æœ€åçš„åˆ†ç±»å±‚ï¼Œé€‚é…æ–°çš„ç±»åˆ«æ•°
        # ROI Head åŒ…å«åˆ†ç±»å’Œè¾¹ç•Œæ¡†å›å½’å™¨
        in_features = model.roi_heads.box_predictor.cls_score.in_features
        
        # æ›¿æ¢åˆ†ç±»å±‚ï¼š91ç±» â†’ num_classesç±»
        model.roi_heads.box_predictor.cls_score = nn.Linear(in_features, num_classes)
        
        # æ›¿æ¢è¾¹ç•Œæ¡†å›å½’å±‚ï¼š91*4 â†’ num_classes*4
        model.roi_heads.box_predictor.bbox_pred = nn.Linear(in_features, num_classes * 4)
        
        print(f"âœ… åŠ è½½é¢„è®­ç»ƒ Faster R-CNN (ResNet50)")
        print(f"   - Backbone: ImageNet é¢„è®­ç»ƒç‰¹å¾æå–å™¨")
        print(f"   - åˆ†ç±»å¤´: ä¿®æ”¹ä¸º {num_classes} ä¸ªç±»åˆ«")
        print(f"   - è¿ç§»å­¦ä¹ ï¼šä¿ç•™ Backboneï¼Œå¾®è°ƒåˆ†ç±»å±‚")
        
        return model
    
    def collate_fn(self, batch):
        """è‡ªå®šä¹‰ collate å‡½æ•°ç”¨äºå¤„ç†å¯å˜å¤§å°çš„ bbox"""
        return tuple(zip(*batch))
    
    def train_one_epoch(self, model, optimizer, train_loader, epoch):
        """è®­ç»ƒä¸€ä¸ª epoch (æ”¯æŒ FP16)"""
        model.train()
        total_loss = 0
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch}/{self.args.epochs}")
        for i, (images, targets) in enumerate(pbar):
            # ç§»åˆ°è®¾å¤‡
            images = [img.to(self.device) for img in images]
            targets = [{k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                       for k, v in t.items()} for t in targets]
            
            optimizer.zero_grad()
            
            # ä½¿ç”¨ autocast è¿›è¡Œ FP16 å‰å‘ä¼ æ’­
            if self.use_fp16:
                with autocast():
                    loss_dict = model(images, targets)
                    losses = sum(loss for loss in loss_dict.values())
                
                # FP16 åå‘ä¼ æ’­
                self.scaler.scale(losses).backward()
                self.scaler.step(optimizer)
                self.scaler.update()
            else:
                # FP32 æ ‡å‡†è®­ç»ƒ
                loss_dict = model(images, targets)
                losses = sum(loss for loss in loss_dict.values())
                
                losses.backward()
                optimizer.step()
            
            total_loss += losses.item()
            pbar.set_postfix({'loss': f'{losses.item():.4f}'})
            
            # æ¸…ç†å†…å­˜
            del images, targets, loss_dict, losses
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        avg_loss = total_loss / len(train_loader)
        print(f"Epoch {epoch}: å¹³å‡æŸå¤± = {avg_loss:.4f}")
        return avg_loss
    
    @torch.no_grad()
    def evaluate(self, model, val_loader, ann_file):
        """éªŒè¯æ¨¡å‹"""
        model.eval()
        
        coco_gt = coco.COCO(ann_file)
        results = []
        
        print("è¯„ä¼°ä¸­...")
        for images, targets in tqdm(val_loader):
            images = [img.to(self.device) for img in images]
            
            outputs = model(images)
            
            for output, target in zip(outputs, targets):
                img_id = target['image_id'].item()
                
                for box, label, score in zip(output['boxes'], output['labels'], output['scores']):
                    x1, y1, x2, y2 = box.cpu().numpy()
                    w = x2 - x1
                    h = y2 - y1
                    
                    results.append({
                        'image_id': int(img_id),
                        'category_id': int(label.item()),
                        'bbox': [float(x1), float(y1), float(w), float(h)],
                        'score': float(score.item()),
                    })
        
        # ä¿å­˜ç»“æœ (è½¬æ¢ä¸º JSON å…¼å®¹çš„ç±»å‹)
        results_file = self.work_dir / 'results.json'
        with open(results_file, 'w') as f:
            json.dump(results, f)
        
        # è¯„ä¼° (éœ€è¦æ·»åŠ  info å­—æ®µ)
        # å¦‚æœåŸå§‹ COCO æ•°æ®ç¼ºå°‘ infoï¼Œæ‰‹åŠ¨æ·»åŠ 
        if 'info' not in coco_gt.dataset:
            coco_gt.dataset['info'] = {
                'description': 'CubiCasa5K detection results',
                'version': '1.0',
                'year': 2024
            }
        
        coco_dt = coco_gt.loadRes(str(results_file))
        coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')
        coco_eval.evaluate()
        coco_eval.accumulate()
        coco_eval.summarize()
        
        return coco_eval.stats[0]  # mAP
    
    def train(self):
        """æ‰§è¡Œè®­ç»ƒ"""
        print(f"\n{'='*70}")
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ")
        print(f"{'='*70}")
        print(f"  éª¨å¹²ç½‘ç»œ: {self.args.backbone}")
        print(f"  æ‰¹é‡å¤§å°: {self.args.batch_size}")
        print(f"  è®­ç»ƒè½®æ•°: {self.args.epochs}")
        print(f"  å­¦ä¹ ç‡: {self.args.lr}")
        print(f"{'='*70}\n")
        
        # æ£€æŸ¥æ•°æ®
        data_root = Path(self.args.data_root)
        coco_dir = data_root  # COCO JSON æ‰€åœ¨ç›®å½•
        # å›¾åƒå®é™…åœ¨ cubicasa5k/cubicasa5k/cubicasa5k ä¸‹ï¼ˆä¸‰å±‚åµŒå¥—ï¼‰
        img_root = data_root.parent / 'cubicasa5k' / 'cubicasa5k'
        
        train_json = coco_dir / 'train_coco_pt.json'
        val_json = coco_dir / 'val_coco_pt.json'
        
        if not train_json.exists() or not val_json.exists():
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨!")
            print(f"   æœŸæœ›: {train_json}, {val_json}")
            sys.exit(1)
        
        if not img_root.exists():
            print(f"âŒ å›¾åƒç›®å½•ä¸å­˜åœ¨!")
            print(f"   æœŸæœ›: {img_root}")
            print(f"   è¯·ç¡®ä¿åŸå§‹å›¾åƒåœ¨åŒä¸€çº§ç›®å½•ä¸‹")
            sys.exit(1)
        
        print(f"âœ… ä½¿ç”¨ COCO æ ‡æ³¨ç›®å½•: {coco_dir}")
        print(f"âœ… ä½¿ç”¨å›¾åƒç›®å½•: {img_root}\n")
        
        # åˆ›å»ºæ•°æ®å¢å¼ºç­–ç•¥ (ä½¿ç”¨ Albumentations - è¾¹ç•Œæ¡†æ„ŸçŸ¥)
        # âœ¨ Albumentations åŸç”Ÿæ”¯æŒ bbox å˜æ¢
        transform_train = A.Compose([
            # å‡ ä½•å˜æ¢ (è‡ªåŠ¨å¤„ç† bbox)
            A.HorizontalFlip(p=0.5),                    # æ°´å¹³ç¿»è½¬
            A.VerticalFlip(p=0.3),                      # ç«–ç›´ç¿»è½¬
            A.Rotate(limit=15, p=0.5, border_mode=0),  # æ—‹è½¬ Â±15åº¦
            A.Affine(
                translate_percent=(0.05, 0.05),
                p=0.5
            ),                                           # å¹³ç§» 5%
            
            # è‰²å½©å¢å¼º
            A.ColorJitter(
                brightness=0.2,
                contrast=0.2,
                saturation=0.1,
                hue=0.05,
                p=0.5
            ),                                           # è‰²å½©æŠ–åŠ¨
            A.GaussianBlur(blur_limit=3, p=0.3),       # é«˜æ–¯æ¨¡ç³Š
            
            # æ ‡å‡†åŒ–å¤„ç†
            A.Normalize(
                mean=[123.675/255, 116.28/255, 103.53/255],
                std=[58.395/255, 57.12/255, 57.375/255],
                always_apply=True
            ),
            ToTensorV2(),
        ], bbox_params=A.BboxParams(
            format='pascal_voc',  # [x1, y1, x2, y2]
            min_visibility=0.3,   # ä¿ç•™å¯è§åº¦ > 30% çš„ bbox
            label_fields=['class_labels']
        ))
        
        # éªŒè¯é›†ä»…è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼ˆæ— å¢å¼ºï¼‰
        transform_val = A.Compose([
            A.Normalize(
                mean=[123.675/255, 116.28/255, 103.53/255],
                std=[58.395/255, 57.12/255, 57.375/255],
                always_apply=True
            ),
            ToTensorV2(),
        ], bbox_params=A.BboxParams(
            format='pascal_voc',
            min_visibility=0.3,
            label_fields=['class_labels']
        ))
        
        train_dataset = COCODetectionDataset(str(img_root), str(train_json), transform_train)
        val_dataset = COCODetectionDataset(str(img_root), str(val_json), transform_val)
        
        train_loader = DataLoader(
            train_dataset,
            batch_size=self.args.batch_size,
            shuffle=True,
            collate_fn=self.collate_fn,
            num_workers=2
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=self.args.batch_size,
            shuffle=False,
            collate_fn=self.collate_fn,
            num_workers=2
        )
        
        print(f"âœ… åŠ è½½æ•°æ®é›†:")
        print(f"   è®­ç»ƒæ ·æœ¬: {len(train_dataset)}")
        print(f"   éªŒè¯æ ·æœ¬: {len(val_dataset)}\n")
        
        # è·å–æ¨¡å‹
        # num_classes=3: 0=background (è‡ªåŠ¨æ·»åŠ ), 1=wall, 2=room
        model = self.get_model(num_classes=3)
        model.to(self.device)
        
        # ä¼˜åŒ–å™¨
        params = [p for p in model.parameters() if p.requires_grad]
        optimizer = optim.SGD(params, lr=self.args.lr, momentum=0.9, weight_decay=5e-4)
        
        # å­¦ä¹ ç‡è°ƒåº¦ (Cosine Annealing - æ›´å¹³æ»‘çš„è¡°å‡)
        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=self.args.epochs,
            eta_min=self.args.lr * 0.01
        )
        
        # è®­ç»ƒå¾ªç¯
        best_ap = 0
        for epoch in range(1, self.args.epochs + 1):
            # è®­ç»ƒ
            avg_loss = self.train_one_epoch(model, optimizer, train_loader, epoch)
            
            # æ›´æ–°å­¦ä¹ ç‡
            scheduler.step()
            
            # éªŒè¯
            if epoch % self.args.val_interval == 0:
                ap = self.evaluate(model, val_loader, str(val_json))
                
                if ap > best_ap:
                    best_ap = ap
                    checkpoint = {
                        'epoch': epoch,
                        'model': model.state_dict(),
                        'optimizer': optimizer.state_dict(),
                        'ap': ap,
                    }
                    torch.save(checkpoint, self.work_dir / 'best_model.pth')
                    print(f"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (AP={ap:.4f})\n")
            
            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if epoch % 3 == 0:
                checkpoint = {
                    'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer': optimizer.state_dict(),
                }
                torch.save(checkpoint, self.work_dir / f'checkpoint_epoch_{epoch}.pth')
        
        print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"   æœ€ä½³ AP: {best_ap:.4f}")
        print(f"   æ¨¡å‹ä¿å­˜åœ¨: {self.work_dir}")


def main():
    parser = argparse.ArgumentParser(description='PyTorch Faster R-CNN è®­ç»ƒè„šæœ¬')
    
    parser.add_argument(
        '--backbone',
        type=str,
        default='resnet50',
        choices=['resnet50'],
        help='éª¨å¹²ç½‘ç»œ (å½“å‰ä»…æ”¯æŒ resnet50)'
    )
    parser.add_argument(
        '--data-root',
        type=str,
        default=r"C:/Users/kawayi_yaling/.cache/kagglehub/datasets/qmarva/cubicasa5k/versions/4/cubicasa5k_coco",
        help='æ•°æ®é›†æ ¹ç›®å½•'
    )
    parser.add_argument(
        '--work-dir',
        type=str,
        default='./pytorch_detection_results',
        help='è¾“å‡ºç›®å½•'
    )
    parser.add_argument(
        '--batch-size',
        type=int,
        default=2,
        help='æ‰¹é‡å¤§å° (é»˜è®¤ 2, å¤§å›¾åƒä¼šè‡ªåŠ¨ç¼©æ”¾è‡³ 1024px)'
    )
    parser.add_argument(
        '--epochs',
        type=int,
        default=1,
        help='è®­ç»ƒè½®æ•°'
    )
    parser.add_argument(
        '--lr',
        type=float,
        default=0.002,
        help='åˆå§‹å­¦ä¹ ç‡'
    )
    parser.add_argument(
        '--gpu',
        type=int,
        default=0,
        help='GPU ID'
    )
    parser.add_argument(
        '--val-interval',
        type=int,
        default=1,
        help='éªŒè¯é—´éš” (epochs)'
    )
    parser.add_argument(
        '--use-fp16',
        action='store_true',
        default=True,
        help='ä½¿ç”¨ FP16 åŠç²¾åº¦è®­ç»ƒ (é»˜è®¤å¯ç”¨)'
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    torch.cuda.manual_seed_all(42)
    np.random.seed(42)
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶æ‰§è¡Œè®­ç»ƒ
    trainer = Trainer(args)
    trainer.train()


if __name__ == '__main__':
    main()
